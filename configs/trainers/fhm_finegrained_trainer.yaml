defaults: &defaults
  accelerator: gpu
  devices: 1
  max_epochs: 1
  accumulate_grad_batches: 1
  limit_val_batches: 1
  limit_train_batches: 1
  enable_checkpointing: True
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: lightning_logs/
      name: fhm-finegrained
      version: epochs30_date1007
      default_hp_metric: false
  callbacks: 
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: checkpoints/fhm/hate
        filename: epochs30_date1007
        monitor: ${monitor_metric}
        mode: max
        save_top_k: 1
        every_n_epochs: 1
        save_last: True
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: ${monitor_metric}
        patience: 5
        mode: max

trainers:
  bart:
    trainer:
      <<: *defaults
      monitor_metric: val_auroc

  flava:
    trainer:
      <<: *defaults
      monitor_metric: hate_validate_AUROC

  lxmert:
    trainer:
      <<: *defaults
      monitor_metric: hate_validate_AUROC

  t5:
    trainer:  
      <<: *defaults
      monitor_metric: val_auroc

  visualbert:
    trainer:
      <<: *defaults
      monitor_metric: hate_validate_AUROC
