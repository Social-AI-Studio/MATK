# lightning.pytorch==2.0.0
seed_everything: 1111
trainer:
  accelerator: gpu
  devices: 1
  max_epochs: 30
  accumulate_grad_batches: 1
  enable_checkpointing: True
  callbacks: 
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: checkpoints/flava/mami
        monitor: shaming_validate_auroc
        mode: max
        save_top_k: 1
        every_n_epochs: 1
        save_last: True
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: shaming_validate_auroc
        patience: 5
        mode: max
model:
  class_path: models.flava.FlavaClassificationModel
  init_args:
    model_class_or_path: facebook/flava-full
    cls_dict: {
      "shaming": 2,
      "misogynous": 2,
      "objectification": 2,
      "violence": 2,
      "stereotype": 2
    }
data:
  class_path: datamodules.modules.ImagesDataModule
  init_args:
    tokenizer_class_or_path: facebook/flava-full
    frcnn_class_or_path: None
    dataset_class: datamodules.datasets.mami.ImagesDataset
    image_dirs: {
      train: /mnt/sdb/aditi/MAMI/training/TRAINING,
      validate: /mnt/sdb/aditi/MAMI/trial/Users/fersiniel/Desktop/MAMITOLABEL/TRIALDATASET/,
      test: /mnt/sdb/aditi/MAMI/test/test,
      predict: /mnt/sdb/aditi/MAMI/test/test,
    }
    annotation_filepaths: {
      train: /mnt/sdb/aditi/MAMI/training/TRAINING/training.csv,
      validate: /mnt/sdb/aditi/MAMI/trial/Users/fersiniel/Desktop/MAMITOLABEL/TRIALDATASET/trial.csv,
      test: /mnt/sdb/aditi/MAMI/test/test/Test.csv,
      predict: /mnt/sdb/aditi/MAMI/test/test/Test.csv,
    }
    auxiliary_dicts: {
      # "caption": "/mnt/sda/datasets/memes/fhm/captions/fhm_clean_captions.pkl"
    }
    shuffle_train: True
    labels:
    - shaming
    - misogynous
    - objectification
    - violence
    - stereotype
    batch_size: 32
    num_workers: 8