# @package _global_
defaults:
  - /model: mistral_clm
  - /dataset:
      - sbic
  - /datamodule: text_generation_datamodule
  - /trainer: single_gpu_trainer
  - /metric:
      - bleu_score
  - /hydra: experiment
  - _self_

# Mandatory Configuration Parameters
model:
  use_lora: False
  use_gradient_checkpointing: False
  optimizers:
    - class_path: torch.optim.Adam
      lr: 2e-5

dataset:
  sbic:
    dataset_class: datasets.sbic.TextDataset
    tokenizer_class_or_path: mistral
    text_template: "{text}"
    labels_template: "{label}"
    labels:
      sbic_implied_statement:
        0: "no"
        1: "yes"

datamodule:
  tokenizer_class_or_path: mistralai/Mistral-7B-v0.1

monitor_metric: validate_sbic_label_average
monitor_mode: max
save_top_ks: 1

# Experiment settings
experiment_name: baseline/sbic/mistral-clm

# Job settings
hydra.verbose: True
seed_everything: 1111
overwrite: False
action: ???