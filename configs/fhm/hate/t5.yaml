# lightning.pytorch==2.0.0
seed_everything: 1111
trainer:
  accelerator: gpu
  devices: 1
  max_epochs: 30
  accumulate_grad_batches: 1
  enable_checkpointing: True
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: lightning_logs/
      name: fhm-finegrained
      version: t5_epochs30_date2306
      default_hp_metric: false
  callbacks: 
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: checkpoints/t5/fhm/hate
        filename: t5_epochs30_date2306
        monitor: val_auroc
        mode: max
        save_top_k: 1
        every_n_epochs: 1
        save_last: True
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_auroc
        patience: 5
        mode: max
model:
  class_path: models.t5.T5ClassificationModel
  init_args:
    model_class_or_path: t5-large
    labels:
    - hate
    label2word: {
      0: "no",
      1: "yes"
    }
data:
  class_path: datamodules.modules.TextDataModule
  init_args:
    tokenizer_class_or_path: t5-large
    dataset_class: datamodules.datasets.fhm_finegrained.TextDataset
    annotation_filepaths: {
      train: /mnt/sdb/aditi/fine_grained_hateful_memes/data/annotations/train.json,
      validate: /mnt/sdb/aditi/fine_grained_hateful_memes/data/annotations/dev_seen.json,
    }
    auxiliary_dicts: {
      # "caption": "/mnt/sda/datasets/memes/fhm/captions/fhm_clean_captions.pkl"
    }
    input_template: "question: is it hateful? context: {text}"
    output_template: "{label}</s>"
    label2word: {
      0: "no",
      1: "yes"
    }
    shuffle_train: True
    batch_size: 32
    labels:
    - hate
    num_workers: 8